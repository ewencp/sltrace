#!/usr/bin/python

import sys
try:
    import simplejson as json
except:
    import json
from uuid import UUID
import vec3
from motion_path import MotionPath

def parse_time(val):
    """
    Parses a time since start from a string in a trace.  Returns the delta
    as a floating point # of seconds.
    """
    assert(val[-2:] == 'ms')
    return (float(val[:-2]) / 1000.0)

def parse_vec3(val):
    """
    Parses a JSON encoded Vector3, returing it as a 3-tuple (x,y,z).
    """
    assert ('x' in val and 'y' in val and 'z' in val)
    return ( float(val['x']), float(val['y']), float(val['z']) )

class ObjectPathTrace:
    """
    ObjectPathTrace provides a convenient interface to object path trace data
    generated by sltrace.  It can load from a file or accept a filtered version
    of a trace.  It is mostly useful as a base for operations on path trace
    data since it mostly provides utility methods including ways to filter the
    raw trace data, extracting certain types of events, events associated with
    specific objects, and methods for cleaning up the raw data (e.g. attempting
    to fill in missing parent information).
    """

    def __init__(self, trace_file=None, raw=None, start_time=None):
        """
        Create a new ObjectPathTrace. Only one source of data should be
        specified.

        Keyword arguments:
        trace_file -- name of JSON trace file
        raw -- raw Python representation of JSON, i.e. an array of
               events (default None)
        start_time -- start time to use for this trace. Overrides any start
                      time specified in the raw trace. (default None)
        """

        # Get raw data
        if raw: self._orig = raw
        elif trace_file:
            try:
                self._orig = json.load(open(trace_file))
            except ValueError:
                self._orig = []
        else: self._orig = []
        # Filter and set start time from data. If specified, override with
        # user start time
        started_evts = [x for x in self._orig if x['event'] == 'started']
        if len(started_evts) > 0:
            self._start_time = started_evts[0]['time'] # FIXME convert to datetime
        if start_time: self._start_time = start_time

        # Cached data:
        # 1) By objects, object categories
        self._objects = None  # List of objects
        self._avatars = None  # List of avatars
        # 2) By event type
        self._additions = None # List of addition events
        self._removals = None # List of removal events
        self._sizes = None # List of size events
        self._locupdates = None # List of loc update events

        self._filled_parents = False

    def objects(self):
        """Returns a list of object UUIDs encountered in this trace."""
        if not self._objects:
            id_set = {}
            for x in self.addition_events():
                if 'id' in x: id_set[UUID(x['id'])] = 1
            self._objects = id_set.keys()

        return self._objects

    def avatars(self):
        """Returns a list of avatar UUIDs encountered in this trace."""
        if not self._avatars:
            id_set = {}
            for x in self.addition_events():
                if (x['type'] == 'avatar' and
                    'id' in x):
                    id_set[UUID(x['id'])] = 1
            self._avatars = id_set.keys()

        return self._avatars

    def object(self, objid):
        """
        Returns a new ObjectPathTrace containing a subset of the original
        events, containing only events pertaining to the specified object.
        """
        object_subset = [x for x in self._orig
                         if 'id' in x and UUID(x['id']) == objid]
        return ObjectPathTrace(raw=object_subset, start_time=self._start_time)

    def subset_traces(self, obj_sets):
        """
        Returns new ObjectPathTraces containing subsets of the
        original events, containing only events pertaining to the
        specified set of objects.
        """

        # Generate reverse index of membership
        obj_groups = {}
        for idx,obj_set in zip(range(len(obj_sets)), obj_sets):
            for obj in obj_set:
                obj_groups[obj] = idx

        group_events = []
        for x in range(len(obj_sets)): group_events.append([])
        for x in self._orig:
            if 'id' not in x: continue
            evt_id = UUID(x['id'])
            # sometimes we get events for which no object had been added
            if evt_id not in obj_groups: continue
            group = obj_groups[evt_id]
            group_events[group].append(x)

        result_traces = []
        for evt_list in group_events:
            result_traces.append(
                ObjectPathTrace(raw=evt_list, start_time=self._start_time)
                )
        return result_traces

    def events(self):
        """Returns a list of all the events in this trace."""
        return self._orig

    def __iter__(self):
        return self._orig.__iter__()

    def events_by_type(self, type_set):
        return [x for x in self._orig if x['event'] in type_set]

    def addition_events(self):
        """Returns a list of addition events in this trace."""
        if not self._additions:
            self._additions = self.events_by_type(['add'])
        return self._additions

    def removal_events(self):
        """Returns a list of kill events in this trace."""
        if not self._removals:
            self._removals = self.events_by_type(['kill'])
        return self._removals

    def size_events(self):
        """Returns a list of size events in this trace."""
        if not self._sizes:
            self._sizes = self.events_by_type(['size'])
        return self._sizes

    def loc_events(self):
        """Returns a list of loc update events in this trace."""
        if not self._locupdates:
            self._locupdates = self.events_by_type(['loc'])
        return self._locupdates


    def fill_parents(self, report=False):
        """
        Attempts to fill in the 'parent' field of addition events with the
        appropriate UUID, based on the 'parent_local' field.  This is necessary
        because sometimes the parent object's local ID hasn't been registered
        when an addition event occurs.
        """
        if self._filled_parents: return

        # Bucket by local parent id in order to do lookups
        unfilled_by_parentid = {}
        for x in self.addition_events():
            if 'parent' in x or 'parent_local' not in x: continue
            if x['parent_local'] not in unfilled_by_parentid:
                unfilled_by_parentid[x['parent_local']] = []
            unfilled_by_parentid[x['parent_local']].append(x)

        # Extract per-parent-id list of events
        parent_additions = {}
        for x in self.addition_events():
            if x['local'] not in unfilled_by_parentid: continue
            if x['local'] not in parent_additions: parent_additions[x['local']] = []
            parent_additions[x['local']].append(x)

        # For each parent id, try to find the nearest and fill in the events
        no_options = 0
        for parentid,events in unfilled_by_parentid.items():
            if parentid not in parent_additions:
                candidate_parents = None
            else:
                candidate_parents = parent_additions[parentid]

            for evt in events:
                added_time = parse_time(evt['time'])
                if candidate_parents == None:
                    no_options += 1
                    continue
                best_candidate = min(candidate_parents, key=lambda x:(parse_time(x['time'])-added_time))
                evt['parent'] = best_candidate['id']

        if no_options > 0 and report:
            print no_options, 'objects found with local parent ID but no matching object.'

        self._filled_parents = True

    def roots(self, ambiguous=False):
        """
        Returns a list of object IDs which are root objects, i.e. they
        do not have a parent ID listed in the trace or they are an
        avatar. (The exception for avatars is necessary since they can
        have a parent if they are sitting on another object.)

        Keyword arguments:
        ambiguous -- if an object has multiple addition events and they have
                     conflicting child status (i.e. at one time it has a parent
                     ID, at another it doesn't), this controls whether it is
                     reported or not. (Default: False, i.e. they will not be
                     reported)
        """

        avatars = self.avatars()
        obj_info = {} # obj -> (had_parent_bool, had_empty_parent_bool)
        for addition in self.addition_events():
            add_id = UUID(addition['id'])

            # Make sure we have a record of the object
            if add_id not in obj_info:
                obj_info[add_id] = (False, False)

            # Check if we need to mark as not having a parent or add parent to list
            if 'parent_local' in addition:
                obj_info[add_id] = (True, obj_info[add_id][1])
            else:
                obj_info[add_id] = (obj_info[add_id][0], True)

        rootobjs = [objid for (objid,parentinfo) in obj_info.items()
                    if objid in avatars or
                    (parentinfo[1] and
                     ((not parentinfo[0]) or (parentinfo[0] and ambiguous))
                     )]

        return rootobjs

    def parents(self):
        """
        Returns a dict mapping object UUID -> parent UUID. For root
        objects the parent UUID is None. The first parent found is
        always reported, i.e.  this method will not handle changes in
        object ownership.  Note that avatars are reported as having
        parents since it is required to compute positions.
        """
        self.fill_parents()

        parent_dict = {}
        # Just scan through additions, adding new found relationships
        for addition in self.addition_events():
            obj_id = UUID(addition['id'])
            if obj_id in parent_dict: continue

            par_id = None
            if ('parent' in addition):
                par_id = UUID(addition['parent'])
            parent_dict[obj_id] = par_id

        return parent_dict

    def root_parents(self):
        """
        Returns a dict mapping object UUID -> root parent UUID. This is similar
        to parents() but compresses the parent hierarchy to two levels: roots
        and children.
        """
        roots = self.roots()
        parent_dict = self.parents()

        flat_parent_dict = {}

        for obj,par in parent_dict.items():
            # Roots are handled easily
            if obj in roots:
                flat_parent_dict[obj] = None
                continue

            # For children we need to find the root
            while(par not in roots and parent_dict[par]):
                par = parent_dict[par]
            flat_parent_dict[obj] = par

        return flat_parent_dict

    def children(self):
        """
        Returns a dict mapping object UUID -> [list, of, child, UUIDs].  Only
        direct children are included and all objects are included, i.e. objects
        with no children have an empty list.
        """
        # We can easily construct what we need from the parent index
        parent_dict = self.parents()
        children_dict = {}

        for obj in parent_dict: children_dict[obj] = []

        for obj,parent in parent_dict.items():
            # Ignore non-existant parents
            if parent not in children_dict: continue

            children_dict[parent].append(obj)

        return children_dict

    def all_children(self, type='roots'):
        """
        Gets a dict from object UUID -> [list, of, all, children, UUIDs].  Note
        that this differs from children() in that it includes children,
        grandchildren, and so on instead of just direct children. By default,
        only root objects will be listed since this is usually the most useful,
        but the type argument allows the user to adjust which are included.

        Keyword arguments:
        type -- specifies the type of objects to get the children of.  Options
                are 'roots' (only root objects, i.e. those without their own
                parents) and 'all' (all objects are included, possible with an
                empty list of children). (Default: 'roots')
        """
        # Use the standard children map as a starting point
        children_dict = self.children()

        all_children_dict = {}
        if type == 'roots':
            for x in self.roots(): all_children_dict[x] = []
        elif type == 'all':
            for x in children_dict: all_children_dict[x] = []

        for par,child_list in all_children_dict.items():
            if par not in all_children_dict: continue
            unprocessed_children = [par]
            while(unprocessed_children):
                next_child = unprocessed_children.pop()
                child_list.extend(children_dict[next_child])
                unprocessed_children.extend(children_dict[next_child])

        return all_children_dict

    def clusters(self):
        """
        Returns a list of lists of objects which are related to each
        other and therefore must be considered together during
        analysis.  Currently the only relationship considered is
        parenthood, but in its strictest sense (not just ownership,
        but also attachment, which is required in order to get
        reliable motion data).

        Each sublist is guaranteed to be disjoint from all other
        sublists.
        """

        self.fill_parents()

        # Our approach is to build up a graph of related objects and
        # then use that graph to isolate connected components as our
        # resulting subsets.

        # We'll maintain the neighbor graph as adjacency lists
        neighbor_graph = {}

        # Some graph helpers...
        def add_vertex(a):
            if a not in neighbor_graph: neighbor_graph[a] = set()

        def add_edge(a, b):
            add_vertex(a)
            add_vertex(b)
            neighbor_graph[a].add(b)
            neighbor_graph[b].add(a)

        # Generate edges based on parent connections, set of all objs
        for evt in self.addition_events():
            child_id = UUID(evt['id'])
            add_vertex(child_id)
            if 'parent' not in evt: continue
            parent_id = UUID(evt['parent'])
            # Add edges in both directions for efficiency
            add_edge(child_id, parent_id)
            add_edge(parent_id, child_id)

        # Get set of connected objects, including r
        def get_connected(r):
            considered = set()
            to_consider = set()
            to_consider.add(r)

            while len(to_consider) > 0:
                considering = to_consider.pop()
                considered.add(considering)

                for connected in neighbor_graph[considering]:
                    if connected not in considered: to_consider.add(connected)

            # Our result is just all the nodes we considered...
            return considered

        # Pick out random elements, compute connected component, and remove those elements
        results = []
        unaccounted = set(neighbor_graph.keys())
        while len(unaccounted) > 0:
            r = unaccounted.pop()
            conn_comp = get_connected(r)
            unaccounted = unaccounted - conn_comp
            results.append(conn_comp)

        return results

    def sizes(self):
        """
        Extract the sizes of each prim in the trace, returning a dict
        of UUID -> (bbox_min_vec, bbox_max_vec), where both are
        3-tuples representing Vector3s. The bounding box will be
        transformed by object transformations (scale, rotate) but will
        not be in world-space (not translated w.r.t. the parent).
        """
        objids = self.objects()
        obj_sizes = {}
        for size_evt in self.size_events():
            size_id = UUID(size_evt['id'])
            if size_id not in objids: continue
            if size_id in obj_sizes: continue # only use the first size value
            bbox_scale = parse_vec3(size_evt['scale'])
            bbox_min = vec3.mult(parse_vec3(size_evt['min']), bbox_scale)
            bbox_max = vec3.mult(parse_vec3(size_evt['max']), bbox_scale)
            r = vec3.dist(bbox_min, bbox_max) * 0.5
            obj_sizes[size_id] = (bbox_min, bbox_max)

        return obj_sizes

    def aggregate_sizes(self):
        """
        Extract the sizes of each "object" in the trace, returning a
        dict of UUID -> (bbox_min_vec, bbox_max_vec). This is similar
        to sizes() but the dict only contains root objects, and the
        sizes include the sizes of the children (with appropriate
        translation w.r.t. the parent.

        Note that this is not guaranteed to be precise, especially
        since the aggregate bounding box can change over time (even
        adding and removing children objects, as well as having them
        move relative to the root object).
        """
        root_children = self.all_children(type='roots')
        obj_sizes = self.sizes()
        additions = self.addition_events()

        # Extract first updates for each object
        first_updates = {}
        for evt in self.loc_events():
            evt_id = UUID(evt['id'])
            if evt_id in first_updates: continue
            first_updates[evt_id] = evt

        # For each parent object, aggregate all child info
        agg_sizes = {}
        for parent,children in root_children.items():
            parent_update = first_updates[parent]
            parent_pos = parse_vec3(parent_update['pos'])
            bbox_min,bbox_max = obj_sizes[parent]
            # We assume that the center of the parent object is the
            # center of the bounding sphere. We just need to compute a
            # radius for each sub object, which is distance
            # (parent_center, child_center) + child radius.
            for child in children:
                if (child not in first_updates): continue
                child_update = first_updates[child]
                child_offset = parse_vec3(child_update['pos'])
                child_bbox_min,child_bbox_max = obj_sizes[child]
                bbox_min = vec3.min(bbox_min, child_bbox_min)
                bbox_max = vec3.min(bbox_max, child_bbox_max)

            agg_sizes[parent] = (bbox_min, bbox_max)

        return agg_sizes

    def motion(self, objid):
        """
        Extract a MotionPath for the object with the specified UUID.
        """
        waypoints = [(parse_time(evt['time']),parse_vec3(evt['pos']))
                     for evt in self.loc_events()
                     if UUID(evt['id']) == objid]
        return MotionPath(start=self._start_time, points=waypoints)

    def motions(self, objid_set):
        """
        Extract MotionPaths for the objects listed in
        objid_set. MotionPaths are returned as a dict of UUID ->
        MotionPath.
        """
        waypoints = dict([(objid,[]) for objid in objid_set])
        for evt in self.loc_events():
            evt_id = UUID(evt['id'])
            if evt_id not in waypoints: continue
            waypoints[evt_id].append( (parse_time(evt['time']),parse_vec3(evt['pos'])) )

        paths = {}
        for objid,waypoints in waypoints.items():
            paths[objid] = MotionPath(start=self._start_time, points=waypoints)

        return paths


    def motion_sequence(self, objid):
        """
        Extract a sequence of MotionPaths for the object with the
        specified UUID. A single MotionPath is generated for location
        updates between each pair of different 'add' events.  In other
        words, a new MotionPath will be started each time a parent
        change occurs, guaranteeing that the values retrieved from a
        single MotionPath won't have weird interpolation problems due
        to switching between sim-local and parent-local coordinates
        for location update.
        """
        return self.motion_sequences([objid])[objid]

    def motion_sequences(self, objids):
        """
        Extract MotionPath sequences for the objects listed in
        objid_set. MotionPaths are returned as a dict of UUID ->
        [MotionPath, list].
        """
        with_pars = self.motion_sequences_with_parents(objids)
        without_pars = {}
        for objid,par_motion_list in with_pars.items():
            pars, motions = zip(*par_motion_list) #unzips parent,motion pairs
            without_pars[objid] = motions
        return without_pars

    def motion_sequences_with_parents(self, objids):
        """
        Extract MotionPath sequences for the objects listed in
        objid_set, including parent information. MotionPaths are
        returned as a dict of UUID -> [(parent1, MotionPath),
        (parent2, MotionPath)].
        """
        objid_set = set(objids)
        # Get all adds, kills, and locs for these objects
        adds_kills_locs = [evt
                           for evt in self.events_by_type(['add', 'kill', 'loc'])
                           if UUID(evt['id']) in objid_set]

        # Split by kills and parent changes for each objid
        # current subsequence for each objid
        cur_subseq = dict([(objid,[]) for objid in objid_set])
        # list of subsequences for each objid
        subseqs = dict([(objid,[]) for objid in objid_set])
        # last parent encountered for each objid
        last_parent = dict([(objid,None) for objid in objid_set])
        for evt in adds_kills_locs:
            evt_id = UUID(evt['id'])
            need_new_subseq = False
            if evt['event'] == 'loc':
                cur_subseq[evt_id].append(evt)
            elif evt['event'] == 'kill': # kills always force a new subseq
                need_new_subseq = True
                new_parent = None
            elif evt['event'] == 'add':
                new_parent = None
                if 'parent' in evt: new_parent = UUID(evt['parent'])
                need_new_subseq = (new_parent != last_parent[evt_id])

            if need_new_subseq:
                if cur_subseq[evt_id]: subseqs[evt_id].append( (last_parent[evt_id], cur_subseq[evt_id]) )
                cur_subseq[evt_id] = []
                last_parent[evt_id] = new_parent
        # if non-empty, append the last subsequence
        for objid,cursub in cur_subseq.items():
            if cursub: subseqs[objid].append( (last_parent[objid],cursub) )

        # Generate waypoint lists from event lists
        results = {}
        for objid,subseqlist in subseqs.items():
            motion_path_list = [ (par,
                                  MotionPath(start=self._start_time,
                                             points = [(parse_time(evt['time']),parse_vec3(evt['pos']))
                                                       for evt in subseq]
                                             )
                                  )
                                 for par,subseq in subseqlist]
            results[objid] = motion_path_list

        # And finally generate motion paths from waypoint lists
        return results

    def sim_motions_iter(self, objids):
        """
        Returns a dict of UUID -> [list, of, motion, paths], where the
        MotionPaths have all been converted to sim coordinates,
        i.e. the importance of parent relationships are removed for
        location data.

        Note that due to ordering, this may not give perfect results.
        This method assumes that fill_parents() has already been
        called, and any missing parents are ignored.
        """
        # We use the list of parent,motion lists for each object to
        # bootstrap. Generate but *don't* squeeze since a relative
        # position that is constant may turn into a varying
        # sim-relative position.
        # FIXME This could be more efficient by computing only the
        # parents, grandparents, etc that are required for the
        # specified object set instead of using self.objects()
        path_seqs = self.motion_sequences_with_parents(self.objects())

        # Returns (parent,motion_path) for the specified object and
        # time, i.e. gets the subsequence at the appropriate time.
        # Note that this doesn't guarantee that time falls between the
        # returned motion_path's start_time() and end_time() since the
        # sequence isn't guaranteed to cover all times.  Instead it
        # returns the one covering the time or the one right before,
        # under the assumption that the object would end up just
        # remaining in the same spot until another update was found.
        def get_par_motion_for_time(objid, time):
            last_par, last_mot = path_seqs[objid][0]
            for par,mot in path_seqs[objid]:
                if time < mot.start_time(): break
                last_par, last_mot = par, mot
            return (last_par,last_mot)

        # Computes an object's position at the specified time by
        # computing each parents position and aggregating them.
        def get_pos_at_time(objid, time):
            # initialize at the bottom, with the object we care about
            # as the 'parent' and position at the origin
            pos = (0.0, 0.0, 0.0)
            par = objid
            while par != None:
                next_par, par_mot = get_par_motion_for_time(par, time)
                pos = vec3.add(pos, par_mot.interpolate(time))
                par = next_par
            return pos

        # And the result of this method will be a dict of lists of
        # MotionPaths, largely just adjustments of those generated by
        # motion_sequences() to be in sim-coordinates.
        for objid in objids:
            mots = path_seqs[objid]
            obj_result = []
            for par,mot in mots:
                sim_locs = []
                for time,pos in mot:
                    sim_locs.append( (time, get_pos_at_time(objid, time)) )
                newmot = MotionPath(mot.start, sim_locs)
                obj_result.append( newmot )
            yield (objid,obj_result)

    def sim_motions(self, objids):
        results = {}
        for objid,obj_result in self.sim_motions_iter(objids):
            results[objid] = obj_result
        return results

def main():
    if len(sys.argv) < 2:
        print "Specify a file."
        return -1

    trace = ObjectPathTrace(sys.argv[1])
    trace.fill_parents(report=True)

    print "Trace file:", sys.argv[1]
    print "Number of objects:", len(trace.objects())
    print "Number of avatars:", len(trace.avatars())
    print "Number of root objects:", len(trace.roots())

    return 0

if __name__ == "__main__":
    sys.exit(main())
